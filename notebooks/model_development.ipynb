{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Scoring Model Development Pipeline\n",
    "\n",
    "This notebook walks through the full model development pipeline step-by-step:\n",
    "\n",
    "1. **Data Loading** - Load parquet, split into Train / Test / OOT\n",
    "2. **Constant Elimination** - Remove zero-variance features\n",
    "3. **Missing Elimination** - Remove high missing-rate features\n",
    "4. **IV Analysis** - Remove low/suspicious Information Value features\n",
    "5. **PSI Stability** - Remove distribution-unstable features (within training data only)\n",
    "6. **Correlation Elimination** - Greedy IV-ordered correlation removal\n",
    "7. **Forward Feature Selection** - XGBoost sequential selection\n",
    "8. **Model Evaluation** - Train / Test / OOT quarterly performance\n",
    "9. **Excel Report** - Generate full report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Setup logging to see pipeline output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)-5s | %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    ")\n",
    "\n",
    "print(f'Project root: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Paths ──\n",
    "INPUT_PATH = str(PROJECT_ROOT / 'data' / 'sample' / 'sample_features.parquet')\n",
    "OUTPUT_DIR = str(PROJECT_ROOT / 'outputs')\n",
    "\n",
    "# ── Data split ──\n",
    "TRAIN_END_DATE = '2024-06-30'   # Everything after this -> OOT quarters\n",
    "TEST_SIZE = 0.20                 # 20% of training period for test set\n",
    "TARGET_COLUMN = 'target'\n",
    "DATE_COLUMN = 'application_date'\n",
    "\n",
    "# ── Elimination thresholds ──\n",
    "IV_MIN = 0.02          # Below -> useless\n",
    "IV_MAX = 0.50          # Above -> suspicious (data leakage risk)\n",
    "MISSING_THRESHOLD = 0.70\n",
    "PSI_THRESHOLD = 0.25   # Critical PSI threshold\n",
    "CORRELATION_THRESHOLD = 0.90\n",
    "AUC_THRESHOLD = 0.0001 # Minimum AUC improvement for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.data_loader import load_and_split\n",
    "\n",
    "datasets = load_and_split(\n",
    "    input_path=INPUT_PATH,\n",
    "    train_end_date=TRAIN_END_DATE,\n",
    "    target_column=TARGET_COLUMN,\n",
    "    date_column=DATE_COLUMN,\n",
    "    test_size=TEST_SIZE,\n",
    ")\n",
    "\n",
    "features = datasets.feature_columns\n",
    "X_train = datasets.train[features]\n",
    "y_train = datasets.train[TARGET_COLUMN]\n",
    "X_test = datasets.test[features]\n",
    "y_test = datasets.test[TARGET_COLUMN]\n",
    "\n",
    "print(f'\\nFeature columns: {len(features)}')\n",
    "print(f'Train: {len(X_train):,} rows, bad rate: {y_train.mean():.2%}')\n",
    "print(f'Test:  {len(X_test):,} rows, bad rate: {y_test.mean():.2%}')\n",
    "print(f'OOT quarters: {datasets.oot_labels}')\n",
    "for label in datasets.oot_labels:\n",
    "    q = datasets.oot_quarters[label]\n",
    "    print(f'  {label}: {len(q):,} rows, bad rate: {q[TARGET_COLUMN].mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at date distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "dates = datasets.train[DATE_COLUMN]\n",
    "dates.dt.to_period('M').value_counts().sort_index().plot(kind='bar', ax=ax, color='steelblue')\n",
    "ax.set_title('Training Data - Monthly Application Counts')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Constant Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.eliminators import ConstantEliminator\n",
    "\n",
    "const_elim = ConstantEliminator()\n",
    "const_result = const_elim.eliminate(X_train, y_train, features)\n",
    "features = const_result.kept_features\n",
    "\n",
    "print(f'Eliminated: {const_result.n_eliminated}')\n",
    "print(f'Remaining:  {const_result.n_kept}')\n",
    "const_result.details_df[const_result.details_df['Status'] == 'Eliminated'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Missing Value Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.eliminators import MissingEliminator\n",
    "\n",
    "missing_elim = MissingEliminator(max_missing_rate=MISSING_THRESHOLD)\n",
    "missing_result = missing_elim.eliminate(X_train, y_train, features)\n",
    "features = missing_result.kept_features\n",
    "\n",
    "print(f'Eliminated: {missing_result.n_eliminated}')\n",
    "print(f'Remaining:  {missing_result.n_kept}')\n",
    "\n",
    "# Missing rate distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "missing_result.details_df['Missing_Rate'].hist(bins=50, ax=ax, color='coral')\n",
    "ax.axvline(x=MISSING_THRESHOLD, color='red', linestyle='--', label=f'Threshold ({MISSING_THRESHOLD:.0%})')\n",
    "ax.set_title('Missing Rate Distribution')\n",
    "ax.set_xlabel('Missing Rate')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. IV (Information Value) Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.eliminators import IVEliminator\n",
    "\n",
    "iv_elim = IVEliminator(min_iv=IV_MIN, max_iv=IV_MAX)\n",
    "iv_result = iv_elim.eliminate(X_train, y_train, features)\n",
    "features = iv_result.kept_features\n",
    "\n",
    "print(f'Eliminated: {iv_result.n_eliminated}')\n",
    "print(f'Remaining:  {iv_result.n_kept}')\n",
    "\n",
    "# Extract IV scores for downstream use\n",
    "iv_scores = {}\n",
    "for _, row in iv_result.details_df.iterrows():\n",
    "    if row.get('IV_Score') is not None:\n",
    "        iv_scores[row['Feature']] = row['IV_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IV distribution of kept features\n",
    "kept_iv = iv_result.details_df[iv_result.details_df['Status'] == 'Kept'].copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Histogram\n",
    "kept_iv['IV_Score'].hist(bins=30, ax=axes[0], color='seagreen')\n",
    "axes[0].set_title('IV Distribution (Kept Features)')\n",
    "axes[0].set_xlabel('IV Score')\n",
    "\n",
    "# IV category counts\n",
    "cat_order = ['weak', 'medium', 'strong']\n",
    "cat_counts = kept_iv['IV_Category'].value_counts().reindex(cat_order).fillna(0)\n",
    "cat_counts.plot(kind='bar', ax=axes[1], color=['#f0ad4e', '#5cb85c', '#5bc0de'])\n",
    "axes[1].set_title('IV Categories (Kept Features)')\n",
    "axes[1].set_ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 20 features by IV\n",
    "print('\\nTop 20 features by IV:')\n",
    "kept_iv.head(20)[['Feature', 'IV_Score', 'IV_Category', 'Univariate_AUC', 'Univariate_KS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. PSI Stability Elimination\n",
    "\n",
    "PSI checks run **within training data only** — OOT is reserved purely for evaluation.\n",
    "\n",
    "### Available PSI Checks\n",
    "\n",
    "| Check | Description |\n",
    "|-------|-------------|\n",
    "| `QuarterlyPSICheck()` | Each quarter vs overall training distribution |\n",
    "| `ConsecutiveQuarterPSICheck()` | Q1 vs Q2, Q2 vs Q3, ... |\n",
    "| `YearlyPSICheck()` | Each year vs overall training |\n",
    "| `HalfSplitPSICheck()` | First half vs second half |\n",
    "| `DateSplitPSICheck('2024-04-01', label='Pre/Post Apr 2024')` | Custom date split |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.eliminators import (\n",
    "    PSIEliminator,\n",
    "    QuarterlyPSICheck,\n",
    "    ConsecutiveQuarterPSICheck,\n",
    "    YearlyPSICheck,\n",
    "    HalfSplitPSICheck,\n",
    "    DateSplitPSICheck,\n",
    ")\n",
    "\n",
    "# Configure PSI checks\n",
    "psi_checks = [\n",
    "    QuarterlyPSICheck(),                                           # Each quarter vs all\n",
    "    ConsecutiveQuarterPSICheck(),                                   # Q(n) vs Q(n+1)\n",
    "    HalfSplitPSICheck(),                                           # First half vs second half\n",
    "    DateSplitPSICheck('2024-04-01', label='Pre/Post Apr 2024'),     # Custom date split\n",
    "]\n",
    "\n",
    "psi_elim = PSIEliminator(\n",
    "    critical_threshold=PSI_THRESHOLD,\n",
    "    checks=psi_checks,\n",
    ")\n",
    "\n",
    "psi_result = psi_elim.eliminate(\n",
    "    X_train, y_train, features,\n",
    "    train_dates=datasets.train[DATE_COLUMN],\n",
    ")\n",
    "features = psi_result.kept_features\n",
    "\n",
    "print(f'Eliminated: {psi_result.n_eliminated}')\n",
    "print(f'Remaining:  {psi_result.n_kept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSI summary - top features by max PSI\n",
    "psi_details = psi_result.details_df.copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "psi_details['Max_PSI'].hist(bins=50, ax=ax, color='mediumpurple')\n",
    "ax.axvline(x=PSI_THRESHOLD, color='red', linestyle='--', label=f'Critical ({PSI_THRESHOLD})')\n",
    "ax.axvline(x=0.10, color='orange', linestyle='--', label='Warning (0.10)')\n",
    "ax.set_title('Max PSI Distribution Across Features')\n",
    "ax.set_xlabel('Max PSI')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show warnings and eliminations\n",
    "warnings_df = psi_details[psi_details['Max_PSI'] >= 0.10].sort_values('Max_PSI', ascending=False)\n",
    "if len(warnings_df) > 0:\n",
    "    print(f'\\nFeatures with PSI >= 0.10 (warnings + eliminations): {len(warnings_df)}')\n",
    "    display(warnings_df[['Feature', 'Max_PSI', 'Mean_PSI', 'Status']].head(20))\n",
    "else:\n",
    "    print('\\nAll features are stable (Max PSI < 0.10)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Correlation Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.eliminators import CorrelationEliminator\n",
    "\n",
    "corr_elim = CorrelationEliminator(max_correlation=CORRELATION_THRESHOLD)\n",
    "corr_result = corr_elim.eliminate(X_train, y_train, features, iv_scores=iv_scores)\n",
    "features = corr_result.kept_features\n",
    "\n",
    "print(f'Eliminated: {corr_result.n_eliminated}')\n",
    "print(f'Remaining:  {corr_result.n_kept}')\n",
    "\n",
    "# Correlated pairs\n",
    "if len(corr_result.details_df) > 0:\n",
    "    print(f'\\nCorrelated pairs eliminated:')\n",
    "    display(corr_result.details_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show remaining features sorted by IV\n",
    "remaining = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'IV': [iv_scores.get(f, 0) for f in features],\n",
    "}).sort_values('IV', ascending=False)\n",
    "\n",
    "print(f'{len(features)} features entering forward selection:\\n')\n",
    "display(remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Forward Feature Selection (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.feature_selector import forward_feature_selection\n",
    "\n",
    "selected_features, selection_df, final_model = forward_feature_selection(\n",
    "    X_train=X_train[features],\n",
    "    y_train=y_train,\n",
    "    X_test=X_test[features],\n",
    "    y_test=y_test,\n",
    "    features=features,\n",
    "    iv_scores=iv_scores,\n",
    "    auc_threshold=AUC_THRESHOLD,\n",
    ")\n",
    "\n",
    "print(f'\\nSelected features: {len(selected_features)}')\n",
    "print(f'Final model test AUC: {selection_df[selection_df[\"Status\"]==\"Added\"][\"AUC_After\"].iloc[-1]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection progress\n",
    "added = selection_df[selection_df['Status'] == 'Added'].copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(added['Cumulative_Features'], added['AUC_After'], 'o-', color='steelblue', markersize=6)\n",
    "ax.set_xlabel('Number of Features')\n",
    "ax.set_ylabel('Test AUC')\n",
    "ax.set_title('Forward Selection: AUC vs Number of Features')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate each point with feature name\n",
    "for _, row in added.iterrows():\n",
    "    ax.annotate(\n",
    "        row['Feature'][:25],\n",
    "        (row['Cumulative_Features'], row['AUC_After']),\n",
    "        fontsize=7, rotation=30, ha='left', va='bottom',\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Full selection table\n",
    "display(added[['Step', 'Feature', 'Feature_IV', 'AUC_After', 'AUC_Improvement']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Model Evaluation (Train / Test / OOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development.evaluator import evaluate_model_quarterly\n",
    "\n",
    "performance_df, lift_tables, importance_df = evaluate_model_quarterly(\n",
    "    model=final_model,\n",
    "    selected_features=selected_features,\n",
    "    train_df=datasets.train,\n",
    "    test_df=datasets.test,\n",
    "    oot_quarters=datasets.oot_quarters,\n",
    "    target_column=TARGET_COLUMN,\n",
    ")\n",
    "\n",
    "print('Model Performance Summary:')\n",
    "display(performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC & Gini across periods\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "x = range(len(performance_df))\n",
    "labels = performance_df['Period'].tolist()\n",
    "\n",
    "# AUC\n",
    "colors = ['steelblue' if 'OOT' not in l else 'coral' for l in labels]\n",
    "axes[0].bar(x, performance_df['AUC'], color=colors)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(labels, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('AUC')\n",
    "axes[0].set_title('AUC Across Periods')\n",
    "axes[0].set_ylim(0.5, 1.0)\n",
    "for i, v in enumerate(performance_df['AUC']):\n",
    "    axes[0].text(i, v + 0.005, f'{v:.4f}', ha='center', fontsize=8)\n",
    "\n",
    "# Gini\n",
    "axes[1].bar(x, performance_df['Gini'], color=colors)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(labels, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Gini')\n",
    "axes[1].set_title('Gini Across Periods')\n",
    "axes[1].set_ylim(0.0, 1.0)\n",
    "for i, v in enumerate(performance_df['Gini']):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.4f}', ha='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "fig, ax = plt.subplots(figsize=(10, max(4, len(importance_df) * 0.4)))\n",
    "imp = importance_df.sort_values('Importance', ascending=True)\n",
    "ax.barh(imp['Feature'], imp['Importance'], color='steelblue')\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Feature Importance (Final Model)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift table for Test set\n",
    "print('Lift Table - Test Set:')\n",
    "display(lift_tables.get('Test', pd.DataFrame()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Generate Excel Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_development import excel_reporter\n",
    "from datetime import datetime\n",
    "\n",
    "run_id = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "excel_path = str(output_dir / f'model_dev_{run_id}.xlsx')\n",
    "\n",
    "# Collect all elimination results\n",
    "elimination_results = [\n",
    "    const_result,\n",
    "    missing_result,\n",
    "    iv_result,\n",
    "    psi_result,\n",
    "    corr_result,\n",
    "]\n",
    "\n",
    "# Build summary\n",
    "train_dates = datasets.train[DATE_COLUMN]\n",
    "oot_labels = ', '.join(datasets.oot_labels) if datasets.oot_labels else 'None'\n",
    "\n",
    "summary = {\n",
    "    'Run Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Run ID': run_id,\n",
    "    'Input File': INPUT_PATH,\n",
    "    'Train End Date': TRAIN_END_DATE,\n",
    "    'Train Period': f\"{train_dates.min().strftime('%Y-%m-%d')} to {train_dates.max().strftime('%Y-%m-%d')}\",\n",
    "    'OOT Periods': oot_labels,\n",
    "    'Train Rows': len(datasets.train),\n",
    "    'Test Rows': len(datasets.test),\n",
    "    'Train Bad Rate': f\"{datasets.train[TARGET_COLUMN].mean():.2%}\",\n",
    "    'Test Bad Rate': f\"{datasets.test[TARGET_COLUMN].mean():.2%}\",\n",
    "    '': '',\n",
    "    'Total Features': len(datasets.feature_columns),\n",
    "    'After Constant Elimination': f\"{const_result.n_kept} ({const_result.n_eliminated} eliminated)\",\n",
    "    'After Missing Elimination': f\"{missing_result.n_kept} ({missing_result.n_eliminated} eliminated)\",\n",
    "    'After IV Elimination': f\"{iv_result.n_kept} ({iv_result.n_eliminated} eliminated)\",\n",
    "    'After PSI Elimination': f\"{psi_result.n_kept} ({psi_result.n_eliminated} eliminated)\",\n",
    "    'After Correlation Elimination': f\"{corr_result.n_kept} ({corr_result.n_eliminated} eliminated)\",\n",
    "    'After Sequential Selection': f\"{len(selected_features)} ({corr_result.n_kept - len(selected_features)} skipped)\",\n",
    "    ' ': '',\n",
    "    'IV Range': f'[{IV_MIN}, {IV_MAX}]',\n",
    "    'Missing Threshold': f'{MISSING_THRESHOLD:.0%}',\n",
    "    'PSI Threshold': str(PSI_THRESHOLD),\n",
    "    'Correlation Threshold': str(CORRELATION_THRESHOLD),\n",
    "    'AUC Threshold': str(AUC_THRESHOLD),\n",
    "}\n",
    "\n",
    "# Add performance metrics to summary\n",
    "for _, row in performance_df.iterrows():\n",
    "    summary[f\"AUC {row['Period']}\"] = row['AUC']\n",
    "    summary[f\"Gini {row['Period']}\"] = row['Gini']\n",
    "\n",
    "corr_pairs_df = getattr(corr_elim, 'corr_pairs_df', None)\n",
    "\n",
    "excel_reporter.generate_report(\n",
    "    output_path=excel_path,\n",
    "    summary=summary,\n",
    "    elimination_results=elimination_results,\n",
    "    corr_pairs_df=corr_pairs_df,\n",
    "    selection_df=selection_df,\n",
    "    performance_df=performance_df,\n",
    "    lift_tables=lift_tables,\n",
    "    importance_df=importance_df,\n",
    ")\n",
    "\n",
    "print(f'Excel report saved to: {excel_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline Funnel Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimination funnel\n",
    "steps = ['Total', 'Constant', 'Missing', 'IV', 'PSI', 'Correlation', 'Selection']\n",
    "counts = [\n",
    "    len(datasets.feature_columns),\n",
    "    const_result.n_kept,\n",
    "    missing_result.n_kept,\n",
    "    iv_result.n_kept,\n",
    "    psi_result.n_kept,\n",
    "    corr_result.n_kept,\n",
    "    len(selected_features),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar(steps, counts, color=['#2c3e50'] + ['#e74c3c']*5 + ['#27ae60'])\n",
    "bars[0].set_color('#2c3e50')\n",
    "bars[-1].set_color('#27ae60')\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 5,\n",
    "            str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Number of Features')\n",
    "ax.set_title('Feature Elimination Funnel')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Started with {counts[0]} features, ended with {counts[-1]} selected features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Alternative: Run Full Pipeline in One Call\n",
    "\n",
    "Instead of running each step manually, you can use the `ModelDevelopmentPipeline` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.model_development.pipeline import ModelDevelopmentPipeline\n",
    "#\n",
    "# pipeline = ModelDevelopmentPipeline(\n",
    "#     input_path=INPUT_PATH,\n",
    "#     train_end_date=TRAIN_END_DATE,\n",
    "#     output_dir=OUTPUT_DIR,\n",
    "#     iv_min=IV_MIN,\n",
    "#     iv_max=IV_MAX,\n",
    "#     missing_threshold=MISSING_THRESHOLD,\n",
    "#     psi_threshold=PSI_THRESHOLD,\n",
    "#     correlation_threshold=CORRELATION_THRESHOLD,\n",
    "#     auc_threshold=AUC_THRESHOLD,\n",
    "#     test_size=TEST_SIZE,\n",
    "#     psi_checks=[\n",
    "#         QuarterlyPSICheck(),\n",
    "#         ConsecutiveQuarterPSICheck(),\n",
    "#         HalfSplitPSICheck(),\n",
    "#         DateSplitPSICheck('2024-04-01', label='Pre/Post Apr 2024'),\n",
    "#     ],\n",
    "# )\n",
    "#\n",
    "# results = pipeline.run()\n",
    "# print(f\"Selected features: {results['after_selection']}\")\n",
    "# print(f\"Excel report: {results['excel_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}